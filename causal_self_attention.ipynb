{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the inputs to the attention mechanism, which represents the respectve vectors of each word in the sequence.\n",
    "inputs = torch.tensor([[ 0.3374, -0.1778, -0.1690],\n",
    "        [ 0.9178,  1.5810,  1.3010],\n",
    "        [ 1.2753, -0.2010, -0.1606],\n",
    "        [-0.4015,  0.9666, -1.1481],\n",
    "        [-1.1589,  0.3255, -0.6315],\n",
    "        [-2.8400, -0.7849, -1.4096]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "atten_weights = torch.tensor([[1.6860e-01, 1.4012e-01, 1.6816e-01, 1.6587e-01, 1.6843e-01, 1.8881e-01],\n",
    "        [9.2893e-04, 9.9621e-01, 1.2864e-03, 9.9685e-04, 5.7419e-04, 5.8191e-06],\n",
    "        [1.3251e-01, 4.2602e-01, 1.4244e-01, 1.2845e-01, 1.1736e-01, 5.3208e-02],\n",
    "        [1.5271e-01, 4.4836e-02, 1.4663e-01, 1.4493e-01, 1.5998e-01, 3.5092e-01],\n",
    "        [9.9106e-02, 8.7224e-03, 8.8134e-02, 9.7618e-02, 1.1824e-01, 5.8818e-01],\n",
    "        [1.8241e-03, 3.4638e-07, 1.1996e-03, 1.7521e-03, 3.4420e-03, 9.9178e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "context_lenght = 6\n",
    "simple_mask = torch.tril(torch.ones(context_lenght, context_lenght))\n",
    "print(simple_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6860e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.2893e-04, 9.9621e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.3251e-01, 4.2602e-01, 1.4244e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.5271e-01, 4.4836e-02, 1.4663e-01, 1.4493e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [9.9106e-02, 8.7224e-03, 8.8134e-02, 9.7618e-02, 1.1824e-01, 0.0000e+00],\n",
      "        [1.8241e-03, 3.4638e-07, 1.1996e-03, 1.7521e-03, 3.4420e-03, 9.9178e-01]])\n"
     ]
    }
   ],
   "source": [
    "atten_weights_masked = atten_weights * simple_mask\n",
    "print(atten_weights_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [5.5097e-03, 9.9907e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [7.8594e-01, 4.2724e-01, 2.0320e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.0575e-01, 4.4965e-02, 2.0918e-01, 2.9632e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [5.8782e-01, 8.7474e-03, 1.2573e-01, 1.9958e-01, 2.8712e-01, 0.0000e+00],\n",
      "        [1.0819e-02, 3.4737e-07, 1.7113e-03, 3.5822e-03, 8.3580e-03, 9.9178e-01]])\n"
     ]
    }
   ],
   "source": [
    "row_sums = atten_weights_masked.sum(dim=1)\n",
    "atten_weights_normalized = atten_weights_masked / row_sums\n",
    "print(atten_weights_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2., 2., 2., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 2., 0.],\n",
      "        [2., 2., 0., 0., 0., 2.],\n",
      "        [2., 0., 0., 0., 0., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5)\n",
    "example = torch.ones(6, 6)\n",
    "print(dropout(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.9981e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0641e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.8115e+00, 8.9929e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.1756e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 6.9475e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(atten_weights_normalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs))\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, context_lenght, dropout, bias = False):\n",
    "        super().__init__()\n",
    "        self.dim_out = dim_out\n",
    "        self.w_query = nn.Linear(dim_in, dim_out, bias= bias)\n",
    "        self.w_key = nn.Linear(dim_in, dim_out, bias= bias)\n",
    "        self.w_value = nn.Linear(dim_in, dim_out, bias= bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_lenght, context_lenght), diagonal= 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch, num_token, d_in = x.shape\n",
    "        \n",
    "        querys = self.w_query(x)\n",
    "        keys = self.w_key(x)\n",
    "        values = self.w_value(x)\n",
    "        \n",
    "        atten_scores = querys @ keys.transpose(1, 2)\n",
    "        atten_weights = torch.softmax(atten_scores, dim= -1)\n",
    "        \n",
    "        atten_weights = self.dropout(atten_weights)\n",
    "\n",
    "        context_vecs = atten_weights @ values\n",
    "        \n",
    "        return context_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.3359e-01,  6.6592e-02,  5.3487e-02, -3.3602e-02, -1.7786e-01,\n",
      "          -8.6936e-02],\n",
      "         [ 9.1773e-02,  7.4496e-02,  1.5637e-01, -5.3266e-02,  2.3278e-02,\n",
      "          -3.8601e-02],\n",
      "         [ 1.1449e-01,  2.2122e-02,  4.3281e-01, -1.0257e-01,  9.1141e-02,\n",
      "          -1.8214e-03],\n",
      "         [ 4.2301e-02,  3.5649e-02,  4.6898e-02, -1.9366e-02,  1.1846e-04,\n",
      "          -2.0548e-02],\n",
      "         [ 9.7960e-01,  1.5314e-01,  1.1931e-02, -6.6993e-02, -9.2484e-01,\n",
      "          -3.4012e-01],\n",
      "         [ 1.5192e-01,  8.5207e-02, -7.4075e-02, -7.3957e-03, -1.3794e-01,\n",
      "          -8.1052e-02]],\n",
      "\n",
      "        [[ 5.2393e-01,  1.1631e-01,  4.2029e-01, -1.3341e-01, -2.8370e-01,\n",
      "          -1.5607e-01],\n",
      "         [ 1.4661e-01,  6.3644e-03,  1.0459e-01, -2.8740e-02, -1.0239e-01,\n",
      "          -3.5758e-02],\n",
      "         [-2.2798e-02,  2.8899e-02, -3.6739e-02,  2.3480e-03,  2.6085e-02,\n",
      "          -6.7021e-03],\n",
      "         [ 3.1075e+00,  6.4244e-01, -1.8788e-01, -1.9788e-01, -2.9344e+00,\n",
      "          -1.1540e+00],\n",
      "         [ 1.7123e+00,  3.6213e-01,  1.3280e-01, -1.6222e-01, -1.5041e+00,\n",
      "          -6.1715e-01],\n",
      "         [ 3.5628e-01,  1.1611e-01, -2.9235e-03, -3.6073e-02, -3.0029e-01,\n",
      "          -1.4537e-01]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_lenght = batch.shape[1]\n",
    "causal_attention = CausalAttention(dim_in=3, dim_out=6, context_lenght=context_lenght,dropout=0.5, bias=0.0)\n",
    "context_vecs = causal_attention(batch)\n",
    "print(context_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
