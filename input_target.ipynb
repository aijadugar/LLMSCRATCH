{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "with open('the-verdict.txt','r', encoding='utf-8') as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print(\"Lenght of the raw text file is :\", len(raw_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8ze5xfGs-5S",
        "outputId": "20e65a56-d3dd-4b87-bab9-c8add0fcb1ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lenght of the raw text file is : 20479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tiktoken"
      ],
      "metadata": {
        "id": "RXGSpSfGtq0W"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding('gpt2')\n",
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(\"The lenght of the encoded token is :\", len(enc_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfDWJ_a9s-2K",
        "outputId": "725821be-b895-4bc2-d271-f7781735893e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lenght of the encoded token is : 5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 6\n",
        "x = enc_text[:context_size]\n",
        "y = enc_text[1:context_size+1]\n",
        "print(\"X :\", x)\n",
        "print(\"Y :\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF8rn6VEs-yT",
        "outputId": "85eb28eb-242f-4ae2-efd2-fac46a5664fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X : [40, 367, 2885, 1464, 1807, 3619]\n",
            "Y : [367, 2885, 1464, 1807, 3619, 402]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size):\n",
        "    input = enc_text[:i]\n",
        "    target = enc_text[i]\n",
        "\n",
        "    print(input, \"--->\", target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUJQIbdss-vC",
        "outputId": "04a16df9-9f09-4d1e-f622-bb4b72cab33c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[40] ---> 367\n",
            "[40, 367] ---> 2885\n",
            "[40, 367, 2885] ---> 1464\n",
            "[40, 367, 2885, 1464] ---> 1807\n",
            "[40, 367, 2885, 1464, 1807] ---> 3619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample = enc_text[:20]\n",
        "for i in range(1, context_size):\n",
        "    input = enc_sample[:i]\n",
        "    target = enc_sample[i]\n",
        "\n",
        "    print(tokenizer.decode(input), \"--->\", tokenizer.decode([target]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njp8g-JLs-qT",
        "outputId": "62878f98-76ce-4241-952b-c5e762eb64f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I --->  H\n",
            "I H ---> AD\n",
            "I HAD --->  always\n",
            "I HAD always --->  thought\n",
            "I HAD always thought --->  Jack\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duAGCWu1rphz",
        "outputId": "5eb7da2e-c939-4395-a227-27153492d9ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "class GPTDataset(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_len, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        token_ids = tokenizer.encode(txt, allowed_special= {\"<|endoftext|>\"})\n",
        "\n",
        "        for i in range(0, len(token_ids)-max_len, stride):\n",
        "            input_chunk = token_ids[i:i + max_len]\n",
        "            target_chunk = [token_ids[i+1:i + max_len + 1]]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.input_ids[index], self.target_ids[index]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader(txt, shuffle=True, max_lenght=256, stride=1, batch_size=4, drop_last=True , num_workers=0):\n",
        "    dataset = GPTDataset(txt, tokenizer, max_lenght, stride)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "w3F4fvh2ru_1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader(raw_text, max_lenght=4, stride=1, batch_size=1, shuffle=False)\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJg1f6QCu9m9",
        "outputId": "f790e4f5-bbb6-4a49-e9f5-f7a9cb010530"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  40,  367, 2885, 1464]]), tensor([[[ 367, 2885, 1464, 1807]]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iplZ6wc-vzSx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}