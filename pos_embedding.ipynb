{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "with open('the-verdict.txt','r', encoding='utf-8') as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print(\"Lenght of the raw text file is :\", len(raw_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8ze5xfGs-5S",
        "outputId": "334d510a-7f3c-4170-b635-cdf2b7a56cac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lenght of the raw text file is : 20479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tiktoken"
      ],
      "metadata": {
        "id": "RXGSpSfGtq0W"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding('gpt2')\n",
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(\"The lenght of the encoded token is :\", len(enc_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfDWJ_a9s-2K",
        "outputId": "03157bf7-8503-4a56-d60d-63a445835e5a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lenght of the encoded token is : 5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 6\n",
        "x = enc_text[:context_size]\n",
        "y = enc_text[1:context_size+1]\n",
        "print(\"X :\", x)\n",
        "print(\"Y :\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF8rn6VEs-yT",
        "outputId": "d10176a6-fdd6-49dd-959e-93b82e8d8434"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X : [40, 367, 2885, 1464, 1807, 3619]\n",
            "Y : [367, 2885, 1464, 1807, 3619, 402]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size):\n",
        "    input = enc_text[:i]\n",
        "    target = enc_text[i]\n",
        "\n",
        "    print(input, \"--->\", target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUJQIbdss-vC",
        "outputId": "2f402fa0-ec04-441a-dae7-37e422fbc2bc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[40] ---> 367\n",
            "[40, 367] ---> 2885\n",
            "[40, 367, 2885] ---> 1464\n",
            "[40, 367, 2885, 1464] ---> 1807\n",
            "[40, 367, 2885, 1464, 1807] ---> 3619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample = enc_text[:20]\n",
        "for i in range(1, context_size):\n",
        "    input = enc_sample[:i]\n",
        "    target = enc_sample[i]\n",
        "\n",
        "    print(tokenizer.decode(input), \"--->\", tokenizer.decode([target]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njp8g-JLs-qT",
        "outputId": "97a1777b-db6d-46a1-96ea-5c9dc883c5e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I --->  H\n",
            "I H ---> AD\n",
            "I HAD --->  always\n",
            "I HAD always --->  thought\n",
            "I HAD always thought --->  Jack\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duAGCWu1rphz",
        "outputId": "aa9c9c64-0d00-44b6-f4e8-98e2e1afbcbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "class GPTDataset(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_len, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        token_ids = tokenizer.encode(txt, allowed_special= {\"<|endoftext|>\"})\n",
        "\n",
        "        for i in range(0, len(token_ids)-max_len, stride):\n",
        "            input_chunk = token_ids[i:i + max_len]\n",
        "            target_chunk = [token_ids[i+1:i + max_len + 1]]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.input_ids[index], self.target_ids[index]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader(txt, shuffle=True, max_lenght=256, stride=1, batch_size=4, drop_last=True , num_workers=0):\n",
        "    dataset = GPTDataset(txt, tokenizer, max_lenght, stride)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "w3F4fvh2ru_1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader(raw_text, max_lenght=4, stride=1, batch_size=8, shuffle=False)\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJg1f6QCu9m9",
        "outputId": "b5f33efe-e3b6-4906-e1ee-0a7059776aad"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[   40,   367,  2885,  1464],\n",
            "        [  367,  2885,  1464,  1807],\n",
            "        [ 2885,  1464,  1807,  3619],\n",
            "        [ 1464,  1807,  3619,   402],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [  402,   271, 10899,  2138],\n",
            "        [  271, 10899,  2138,   257]]), tensor([[[  367,  2885,  1464,  1807]],\n",
            "\n",
            "        [[ 2885,  1464,  1807,  3619]],\n",
            "\n",
            "        [[ 1464,  1807,  3619,   402]],\n",
            "\n",
            "        [[ 1807,  3619,   402,   271]],\n",
            "\n",
            "        [[ 3619,   402,   271, 10899]],\n",
            "\n",
            "        [[  402,   271, 10899,  2138]],\n",
            "\n",
            "        [[  271, 10899,  2138,   257]],\n",
            "\n",
            "        [[10899,  2138,   257,  7026]]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257\n",
        "vector_dim = 256"
      ],
      "metadata": {
        "id": "iplZ6wc-vzSx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "embedding = torch.nn.Embedding(vocab_size, vector_dim)"
      ],
      "metadata": {
        "id": "y5_0TgBOzLX7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXQwwI1_zOkC",
        "outputId": "20641652-44a1-406f-ec96-b0496f67260c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(50257, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(dataloader)\n",
        "input, target = next(data_iter)"
      ],
      "metadata": {
        "id": "bNXKAQE6zXKL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Token IDs :\", input)\n",
        "print(\"Input shape :\", input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP_3Leliz72e",
        "outputId": "a2618c35-f9a8-4c8f-bad9-4efe55bd073f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs : tensor([[   40,   367,  2885,  1464],\n",
            "        [  367,  2885,  1464,  1807],\n",
            "        [ 2885,  1464,  1807,  3619],\n",
            "        [ 1464,  1807,  3619,   402],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [  402,   271, 10899,  2138],\n",
            "        [  271, 10899,  2138,   257]])\n",
            "Input shape : torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embedding = embedding(input)"
      ],
      "metadata": {
        "id": "VS_t3GKP0I-f"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(token_embedding)\n",
        "print(\"Token embedding shape :\", token_embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq1Z5HJF0reR",
        "outputId": "4cf97be5-1388-41c2-b7b8-79313c9b4449"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.2949, -0.6371,  1.1273,  ..., -0.5957,  1.0866,  1.2326],\n",
            "         [-1.1192, -1.4326,  0.3014,  ..., -0.9827, -0.7535, -0.2734],\n",
            "         [ 0.3082, -0.2574,  1.4615,  ..., -0.7029,  0.9989,  0.3827],\n",
            "         [-0.9967, -0.9794,  0.7152,  ...,  0.3941, -0.5527, -0.4929]],\n",
            "\n",
            "        [[-1.1192, -1.4326,  0.3014,  ..., -0.9827, -0.7535, -0.2734],\n",
            "         [ 0.3082, -0.2574,  1.4615,  ..., -0.7029,  0.9989,  0.3827],\n",
            "         [-0.9967, -0.9794,  0.7152,  ...,  0.3941, -0.5527, -0.4929],\n",
            "         [ 0.8151,  0.8998, -0.9503,  ..., -0.5637,  0.6895, -1.8415]],\n",
            "\n",
            "        [[ 0.3082, -0.2574,  1.4615,  ..., -0.7029,  0.9989,  0.3827],\n",
            "         [-0.9967, -0.9794,  0.7152,  ...,  0.3941, -0.5527, -0.4929],\n",
            "         [ 0.8151,  0.8998, -0.9503,  ..., -0.5637,  0.6895, -1.8415],\n",
            "         [ 0.9071, -1.5982, -0.5144,  ..., -0.4843, -0.0918,  0.7356]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.9071, -1.5982, -0.5144,  ..., -0.4843, -0.0918,  0.7356],\n",
            "         [-0.6158, -1.4339, -0.0114,  ..., -0.4675,  0.1354,  1.0596],\n",
            "         [-1.2909,  0.4065, -1.2704,  ...,  0.3555,  1.6355, -1.1189],\n",
            "         [-0.4866,  0.1322,  0.3354,  ..., -0.3422,  1.1085,  0.0672]],\n",
            "\n",
            "        [[-0.6158, -1.4339, -0.0114,  ..., -0.4675,  0.1354,  1.0596],\n",
            "         [-1.2909,  0.4065, -1.2704,  ...,  0.3555,  1.6355, -1.1189],\n",
            "         [-0.4866,  0.1322,  0.3354,  ..., -0.3422,  1.1085,  0.0672],\n",
            "         [-1.2871,  1.0045, -0.8073,  ...,  1.4454, -0.3183,  0.8490]],\n",
            "\n",
            "        [[-1.2909,  0.4065, -1.2704,  ...,  0.3555,  1.6355, -1.1189],\n",
            "         [-0.4866,  0.1322,  0.3354,  ..., -0.3422,  1.1085,  0.0672],\n",
            "         [-1.2871,  1.0045, -0.8073,  ...,  1.4454, -0.3183,  0.8490],\n",
            "         [-0.0969,  0.3367,  0.3290,  ..., -1.0906, -1.5478, -1.0565]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Token embedding shape : torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contex_lenght = 4\n",
        "pos_embedding_layer = torch.nn.Embedding(contex_lenght, vector_dim)\n",
        "pos_embedding = pos_embedding_layer(torch.arange(contex_lenght))\n",
        "print(pos_embedding)\n",
        "print(\"Position embedding shape :\", pos_embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY2ypENv0vyq",
        "outputId": "ac4263e3-5754-445a-fee7-642424085a25"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3392,  0.1320,  0.6272,  ...,  1.2820, -0.9503, -0.8034],\n",
            "        [ 0.4378, -0.6656, -0.9534,  ...,  0.5473, -0.1866,  0.6743],\n",
            "        [ 0.6322,  1.0047,  1.1380,  ..., -0.0900, -0.6761, -0.1072],\n",
            "        [ 0.0190,  0.0084,  1.8822,  ...,  0.4092,  0.9876,  0.2764]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Position embedding shape : torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pG-uQCFK1pzG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}