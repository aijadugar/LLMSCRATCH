{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the inputs to the attention mechanism, which represents the respectve vectors of each word in the sequence.\n",
    "inputs = torch.tensor([[ 0.3374, -0.1778, -0.1690],\n",
    "        [ 0.9178,  1.5810,  1.3010],\n",
    "        [ 1.2753, -0.2010, -0.1606],\n",
    "        [-0.4015,  0.9666, -1.1481],\n",
    "        [-1.1589,  0.3255, -0.6315],\n",
    "        [-2.8400, -0.7849, -1.4096]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1]\n",
    "dim_in = inputs.shape[1]\n",
    "dim_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665]]) Parameter containing:\n",
      "tensor([[0.1366, 0.1025],\n",
      "        [0.1841, 0.7264],\n",
      "        [0.3153, 0.6871]]) Parameter containing:\n",
      "tensor([[0.0756, 0.1966],\n",
      "        [0.3164, 0.4017],\n",
      "        [0.1186, 0.8274]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "w_query = torch.nn.Parameter(torch.rand(dim_in, dim_out), requires_grad = False)\n",
    "w_key = torch.nn.Parameter(torch.rand(dim_in, dim_out), requires_grad = False)\n",
    "w_value = torch.nn.Parameter(torch.rand(dim_in, dim_out), requires_grad = False)\n",
    "print(w_query, w_key, w_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7659, 2.6901]) tensor([0.8265, 2.1365]) tensor([0.7239, 1.8921])\n"
     ]
    }
   ],
   "source": [
    "query_of_x_2 = x_2 @ w_query\n",
    "key_of_x_2 = x_2 @ w_key\n",
    "value_of_x_2 = x_2 @ w_value\n",
    "print(query_of_x_2, key_of_x_2, value_of_x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0427, -0.0946],\n",
      "        [ 0.7659,  2.6901],\n",
      "        [ 0.3152,  0.3812],\n",
      "        [ 0.0394, -0.5367],\n",
      "        [-0.3080, -0.9217],\n",
      "        [-1.1428, -3.2289]]) tensor([[-0.0399, -0.2107],\n",
      "        [ 0.8265,  2.1365],\n",
      "        [ 0.0866, -0.1257],\n",
      "        [-0.2389, -0.1278],\n",
      "        [-0.2975, -0.3162],\n",
      "        [-0.9767, -1.8298]]) tensor([[-0.0508, -0.1449],\n",
      "        [ 0.7239,  1.8921],\n",
      "        [ 0.0138,  0.0371],\n",
      "        [ 0.1393, -0.6406],\n",
      "        [-0.0595, -0.6196],\n",
      "        [-0.6303, -2.0401]])\n",
      "torch.Size([6, 2]) torch.Size([6, 2]) torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "querys = inputs @ w_query\n",
    "keys = inputs @ w_key\n",
    "values = inputs @ w_value\n",
    "print(querys, keys, values)\n",
    "print(querys.shape, keys.shape, values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.3803)\n"
     ]
    }
   ],
   "source": [
    "atten_of_x_2 = query_of_x_2.dot(key_of_x_2)\n",
    "print(atten_of_x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8226e-02, -1.6681e-01,  1.5579e-02,  1.8998e-03,  1.7218e-02,\n",
      "          1.3139e-01],\n",
      "        [-5.9739e-01,  6.3803e+00, -2.7178e-01, -5.2682e-01, -1.0784e+00,\n",
      "         -5.6703e+00],\n",
      "        [-9.2905e-02,  1.0749e+00, -2.0629e-02, -1.2401e-01, -2.1429e-01,\n",
      "         -1.0054e+00],\n",
      "        [ 1.1151e-01, -1.1140e+00,  7.0863e-02,  5.9182e-02,  1.5798e-01,\n",
      "          9.4350e-01],\n",
      "        [ 2.0651e-01, -2.2238e+00,  8.9181e-02,  1.9139e-01,  3.8307e-01,\n",
      "          1.9873e+00],\n",
      "        [ 7.2598e-01, -7.8431e+00,  3.0688e-01,  6.8573e-01,  1.3610e+00,\n",
      "          7.0244e+00]])\n"
     ]
    }
   ],
   "source": [
    "all_atten = querys @ keys.T\n",
    "print(all_atten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6860e-01, 1.4012e-01, 1.6816e-01, 1.6587e-01, 1.6843e-01, 1.8881e-01],\n",
      "        [9.2893e-04, 9.9621e-01, 1.2864e-03, 9.9685e-04, 5.7419e-04, 5.8191e-06],\n",
      "        [1.3251e-01, 4.2602e-01, 1.4244e-01, 1.2845e-01, 1.1736e-01, 5.3208e-02],\n",
      "        [1.5271e-01, 4.4836e-02, 1.4663e-01, 1.4493e-01, 1.5998e-01, 3.5092e-01],\n",
      "        [9.9106e-02, 8.7224e-03, 8.8134e-02, 9.7618e-02, 1.1824e-01, 5.8818e-01],\n",
      "        [1.8241e-03, 3.4638e-07, 1.1996e-03, 1.7521e-03, 3.4420e-03, 9.9178e-01]])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "atten_weights = torch.softmax(all_atten, dim = 1)                                            \n",
    "print(atten_weights)\n",
    "print(atten_weights[2].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7212, 1.8838])\n"
     ]
    }
   ],
   "source": [
    "context_of_x_2 = atten_weights[1] @ values\n",
    "print(context_of_x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        self.w_query = nn.Parameter(torch.rand(dim_in, dim_out), requires_grad = False)\n",
    "        self.w_key = nn.Parameter(torch.rand(dim_in, dim_out), requires_grad = False)\n",
    "        self.w_value = nn.Parameter(torch.rand(dim_in, dim_out), requires_grad = False)\n",
    "    def forward(self, x):\n",
    "        querys = x @ self.w_query\n",
    "        keys = x @ self.w_key\n",
    "        values = x @ self.w_value\n",
    "        all_atten = querys @ keys.T\n",
    "        atten_weights = torch.softmax(all_atten, dim = 1)\n",
    "        context_vecs = atten_weights @ values\n",
    "        return context_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0107, -0.3489],\n",
      "        [ 0.7212,  1.8838],\n",
      "        [ 0.2810,  0.5286],\n",
      "        [-0.1838, -0.8397],\n",
      "        [-0.3617, -1.3303],\n",
      "        [-0.6251, -2.0268]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "self_attention = SelfAttention_v1(dim_in, dim_out)\n",
    "print(self_attention(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        self.w_query = nn.Linear(dim_in, dim_out, bias = False)\n",
    "        self.w_key = nn.Linear(dim_in, dim_out, bias = False)\n",
    "        self.w_value = nn.Linear(dim_in, dim_out, bias = False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        querys = self.w_query(x)\n",
    "        keys = self.w_key(x)\n",
    "        values = self.w_value(x)\n",
    "\n",
    "        all_atten = querys @ keys.T\n",
    "        atten_weights = torch.softmax(all_atten, dim = 1)\n",
    "        context_vecs = atten_weights @ values\n",
    "        return context_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1359,  0.0974],\n",
      "        [-0.1075,  0.2320],\n",
      "        [-0.0438,  0.1442],\n",
      "        [-0.2889, -0.0032],\n",
      "        [-0.3373, -0.0185],\n",
      "        [-0.6094, -0.1934]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "self_attention_v2 = SelfAttention_v2(dim_in, dim_out)\n",
    "print(self_attention_v2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
